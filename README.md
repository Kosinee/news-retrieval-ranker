# üß† News Retrieval & Ranking System (MLOps Project)

## üìå –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
–¶–µ–ª—å ‚Äî –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–Ω–æ–≥–æ—Å—Ç—É–ø–µ–Ω—á–∞—Ç—É—é —Å–∏—Å—Ç–µ–º—É **–ø–æ–∏—Å–∫–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–æ–≤–æ—Å—Ç–µ–π**,  
–∫–æ—Ç–æ—Ä–∞—è —É–º–µ–µ—Ç:
1. –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (retrieval);
2. –∏—Ö –ø–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞—Ç—å (reranking);
3. –æ–±—É—á–∞—Ç—å—Å—è –≤ —Ä–µ–∂–∏–º–µ **continuous training** –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –ª–æ–≥–∞–º.

–û—Å–Ω–æ–≤–∞ –¥–∞–Ω–Ω—ã—Ö ‚Äî **[MIND Dataset (Microsoft News)](https://msnews.github.io/)**,  
–≤ –∫–æ—Ç–æ—Ä–æ–º —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –æ–ø–∏—Å–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –∫–ª–∏–∫–∏ (impressions).

---

## üíº –ë–∏–∑–Ω–µ—Å-—Ü–µ–ª—å
–£–≤–µ–ª–∏—á–∏—Ç—å **CTR (Click-Through Rate)** –∏ **–≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π**  
–∑–∞ —Å—á—ë—Ç –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –≤—ã–¥–∞—á–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ.  
–¶–µ–ª—å:
- +10-15 % CTR uplift –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline (BM25)

---

## üß© –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1Ô∏è‚É£ Candidate Generators
| –ú–æ–¥–µ–ª—å | –¢–∏–ø | –¶–µ–ª—å | –õ–æ—Å—Å | –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ |
|--------|------|------|------|------------------|
| **BM25** | Keyword | –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤–∞—è –±–ª–∏–∑–æ—Å—Ç—å | ‚Äî | Recall@K |
| **DSSM_sem** | Bi-encoder | —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å | `InfoNCE` | Recall@K |
| **DSSM_pref** | Bi-encoder | –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ –∫–ª–∏–∫–∞–º | `TripletLoss` | Recall@K |

---

### 2Ô∏è‚É£ Reranker / Ranker
| –ú–æ–¥–µ–ª—å | –¢–∏–ø | –õ–æ—Å—Å | –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç | –ú–µ—Ç—Ä–∏–∫–∏ |
|--------|------|------|---------------|----------|
| **LightGBM LambdaMART** | Listwise Ranker | `LambdaMART Loss` | NDCG | NDCG@10, MRR, MAP |

**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**
- —Å–∫–æ—Ä—ã –æ—Ç BM25, DSSM_sem, DSSM_pref;  
- CTR –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ —Ñ–∏—á–∏);  
- –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ / –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ);  

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏

| –£—Ä–æ–≤–µ–Ω—å | –ú–µ—Ç—Ä–∏–∫–∏ | –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è | –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è |
|----------|----------|---------------|------------------|
| **Retriever** | Recall@100, MRR@10 | –ø–æ–ª–Ω–æ—Ç–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç—å –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö | Recall‚â•0.9 |
| **Ranker** | NDCG@10, MRR@10 | –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ—Ä—è–¥–∫–∞ –≤ –≤—ã–¥–∞—á–µ | NDCG@10‚âà0.55 |
| **–ë–∏–∑–Ω–µ—Å** | CTR | –≤–æ–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π | +10‚Äì15 % CTR uplift |
| **–°–µ—Ä–≤–∏—Å–Ω—ã–µ** | Latency | —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞–π–ø–ª–∞–π–Ω–∞ | ‚â§ 200 –º—Å |

---

## üîÅ Continuous Training Workflow

1. **–°–±–æ—Ä –Ω–æ–≤—ã—Ö –ª–æ–≥–æ–≤** –∏–∑ –ø—Ä–æ–¥–∞–∫—à–Ω-–ø–æ—Ç–æ–∫–∞ (–∏–º–ø—Ä–µ—Å—Å–∏–∏, –∫–ª–∏–∫–∏).  
2. **Data Prep Job** ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü features.  
3. **Retraining retrievers** (DSSM_sem / DSSM_pref) –ø–æ —Å–≤–µ–∂–∏–º –ª–æ–≥–∞–º.  
4. **Retraining ranker** (LightGBM LambdaMART).  
5. **Evaluation** –Ω–∞ hold-out –Ω–µ–¥–µ–ª–µ.  
6. **Auto-deploy** –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ NDCG@10 > threshold.  

---

## ‚öôÔ∏è –ü—Ä–∏–º–µ—Ä –æ–±—É—á–µ–Ω–∏—è —Ä–∞–Ω–∂–∏—Ä–æ–≤—â–∏–∫–∞ (LightGBM)

```python
import lightgbm as lgb

params = {
    "objective": "lambdarank",
    "metric": "ndcg",
    "ndcg_eval_at": [10],
    "num_leaves": 63,
    "learning_rate": 0.05,
    "feature_fraction": 0.9
}

train = lgb.Dataset(X_train, label=y_train, group=group_train)
valid = lgb.Dataset(X_valid, label=y_valid, group=group_valid)

model = lgb.train(params, train, valid_sets=[valid],
                  num_boost_round=200, early_stopping_rounds=30)
